{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP3Tul/Mi4Jbtnp8yMnhzYB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EKtDwQAyTTUJ","executionInfo":{"status":"ok","timestamp":1743913381485,"user_tz":-540,"elapsed":7822,"user":{"displayName":"佐藤廉","userId":"11241164536858674651"}},"outputId":"c8351973-a658-4d6e-c149-c228eb037d8e"},"outputs":[{"output_type":"stream","name":"stdout","text":["整形完了！ファイル名： kokoro_clean.txt\n"]}],"source":["# Step 1: 必要なライブラリをインポート\n","import re\n","import urllib.request\n","\n","# Step 2: 青空文庫の「こころ」テキストデータ（ルビあり）をダウンロード\n","url = \"https://www.aozora.gr.jp/cards/000148/files/773_14560.html\"\n","file_name = \"kokoro_raw.html\"\n","urllib.request.urlretrieve(url, file_name)\n","\n","# Step 3: HTMLから本文テキストだけを取り出す\n","from bs4 import BeautifulSoup\n","\n","with open(file_name, encoding='shift_jis') as f:\n","  soup = BeautifulSoup(f, \"html.parser\")\n","  # テキスト抽出 (<div class=\"main_text>\") から\n","  text = soup.find(\"div\", class_=\"main_text\").get_text()\n","\n","# Step 4: ルビ削除関数\n","def remove_ruby(text):\n","  text = re.sub(r'｜([^《]+)《[^》]+》', r'\\1', text)\n","  text = re.sub(r'《[^》]+》', '', text)\n","  return text\n","\n","# Step 5: ヘッダー・フッター・空行を削除\n","def clean_text(text):\n","  text = remove_ruby(text)\n","  # 不要な空行や記号を消す\n","  text = re.sub(r'\\n\\s*\\n', '\\n', text)\n","  text = re.sub(r'［＃.*?］', '', text)  # 青空注記\n","  return text.strip()\n","\n","# Step 6: 実行して整形\n","cleaned = clean_text(text)\n","\n","# Step 7: 保存(GPT学習用にテキストファイル化)\n","with open(\"kokoro_clean.txt\", \"w\", encoding=\"utf-8\") as f:\n","  f.write(cleaned)\n","\n","print(\"整形完了！ファイル名： kokoro_clean.txt\")"]},{"cell_type":"code","source":["# 夏目漱石「坊ちゃん」をダウンロード\n","url = \"https://www.aozora.gr.jp/cards/000148/files/752_14964.html\"\n","file_name = \"botchan_raw.html\"\n","urllib.request.urlretrieve(url, file_name)\n","\n","# HTMLから本文を取り出す\n","with open(file_name, encoding='shift_jis') as f:\n","    soup = BeautifulSoup(f, \"html.parser\")\n","    text = soup.find(\"div\", class_=\"main_text\").get_text()\n","\n","# テキスト整形関数を再利用\n","cleaned_botchan = clean_text(text)\n","\n","# 保存\n","with open(\"botchan_clean.txt\", \"w\", encoding=\"utf-8\") as f:\n","    f.write(cleaned_botchan)\n","\n","print(\"坊ちゃん整形完了！\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jqMtBUjBNtmG","executionInfo":{"status":"ok","timestamp":1743928318347,"user_tz":-540,"elapsed":4407,"user":{"displayName":"佐藤廉","userId":"11241164536858674651"}},"outputId":"cbf522f2-131d-4bfa-e318-bbe2ee66e795"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["坊ちゃん整形完了！\n"]}]},{"cell_type":"code","source":["# 夏目漱石「正岡子規」をダウンロード\n","url = \"https://www.aozora.gr.jp/cards/000148/files/1751_6496.html\"\n","file_name = \"masaoka_raw.html\"\n","urllib.request.urlretrieve(url, file_name)\n","\n","# HTMLから本文を取り出す\n","with open(file_name, encoding='shift_jis') as f:\n","    soup = BeautifulSoup(f, \"html.parser\")\n","    text = soup.find(\"div\", class_=\"main_text\").get_text()\n","\n","# テキスト整形関数を再利用\n","cleaned_masaoka = clean_text(text)\n","\n","# 保存\n","with open(\"masaoka_clean.txt\", \"w\", encoding=\"utf-8\") as f:\n","    f.write(cleaned_botchan)\n","\n","print(\"正岡子規整形完了！\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TyAkbefASzKm","executionInfo":{"status":"ok","timestamp":1743929523923,"user_tz":-540,"elapsed":1320,"user":{"displayName":"佐藤廉","userId":"11241164536858674651"}},"outputId":"a42fd0f6-d0af-4026-83f8-cb0f4edcc64d"},"execution_count":98,"outputs":[{"output_type":"stream","name":"stdout","text":["正岡子規整形完了！\n"]}]},{"cell_type":"code","source":["# こころと、坊ちゃん、正岡子規のデータを結合\n","with open(\"kokoro_clean.txt\", \"r\", encoding=\"utf-8\") as f:\n","  kokoro_text = f.read()\n","\n","with open(\"botchan_clean.txt\", \"r\", encoding=\"utf-8\") as f:\n","  botchan_text = f.read()\n","\n","with open(\"masaoka_clean.txt\", \"r\", encoding=\"utf-8\") as f:\n","  masaoka_text = f.read()\n","\n","# 結合\n","combined_text = kokoro_text + \"\\n\" + botchan_text + \"\\n\" + masaoka_text\n","\n","# 保存\n","with open(\"combined_clean.txt\", \"w\", encoding=\"utf-8\") as f:\n","  f.write(combined_text)\n","\n","print(\"データ結合完了!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7-FsWZfqOn6z","executionInfo":{"status":"ok","timestamp":1743929583601,"user_tz":-540,"elapsed":48,"user":{"displayName":"佐藤廉","userId":"11241164536858674651"}},"outputId":"327bf7c1-78ff-490e-c52e-771edb8e7956"},"execution_count":99,"outputs":[{"output_type":"stream","name":"stdout","text":["データ結合完了!\n"]}]},{"cell_type":"code","source":["# ファイル読み込み\n","with open(\"combined_clean.txt\", encoding=\"utf-8\") as f:\n","  text = f.read()\n","\n","# ユニークな文字を取り出す\n","chars = sorted(list(set(text)))\n","\n","# 空白文字を追加\n","chars.append(' ')\n","vocab_size = len(chars)\n","\n","# 文字 ⇔ ID の辞書を作る\n","stoi = {ch: i for i, ch in enumerate(chars)}  # string to int\n","itos = {i: ch for ch, i in stoi.items()}       # int to string\n","\n","# エンコード・デコード関数\n","def encode(s):\n","  return [stoi[c] for c in s]\n","\n","def decode(ids):\n","  return ''.join([itos[i] for i in ids])\n","\n","print(f\"語彙サイズ（ユニークな文字数）: {vocab_size}\")\n","print(f\"例:「私」→ {encode('私')}, {decode(encode('私'))}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"33k1H4k_Vit4","executionInfo":{"status":"ok","timestamp":1743929590837,"user_tz":-540,"elapsed":38,"user":{"displayName":"佐藤廉","userId":"11241164536858674651"}},"outputId":"7be27d2c-5996-4ab3-a22f-9e5f9c5a6af7"},"execution_count":100,"outputs":[{"output_type":"stream","name":"stdout","text":["語彙サイズ（ユニークな文字数）: 2465\n","例:「私」→ [1623], 私\n"]}]},{"cell_type":"code","source":["# バッチ作成用のコード\n","import torch\n","\n","# データ全体の数値化（前処理済み）\n","data = torch.tensor(encode(text), dtype=torch.long)\n","\n","# 訓練用と検証用に分ける（9:1くらい）\n","n = int(0.9 * len(data))\n","train_data = data[:n]\n","val_data = data[n:]\n","\n","# シーケンス長（どれくらいの長さで学習するか）\n","block_size = 8\n","\n","# バッチ作成関数\n","def get_batch(split, batch_size=4):\n","  data_split = train_data if split == 'train' else val_data\n","  ix = torch.randint(len(data_split) - block_size, (batch_size,))\n","\n","  x = torch.stack([data_split[i:i+block_size] for i in ix])\n","  y = torch.stack([data_split[i+1:i+block_size+1] for i in ix])\n","\n","  return x, y"],"metadata":{"id":"FbarNSw8aSc7","executionInfo":{"status":"ok","timestamp":1743929594723,"user_tz":-540,"elapsed":71,"user":{"displayName":"佐藤廉","userId":"11241164536858674651"}}},"execution_count":101,"outputs":[]},{"cell_type":"code","source":["# バッチ作成\n","data = torch.tensor(encode(text), dtype=torch.long)\n","\n","# 訓練用と検証用に分ける（9:1くらい）\n","n = int(0.9 * len(data))\n","train_data = data[:n]\n","val_data = data[n:]\n","\n","# バッチ作成関数\n","def get_batch(split, batch_size=4):\n","    data_split = train_data if split == 'train' else val_data\n","    ix = torch.randint(len(data_split) - block_size, (batch_size,))\n","\n","    x = torch.stack([data_split[i:i+block_size] for i in ix])\n","    y = torch.stack([data_split[i+1:i+block_size+1] for i in ix])\n","\n","    return x, y"],"metadata":{"id":"EqkpkBwePxl2","executionInfo":{"status":"ok","timestamp":1743929597073,"user_tz":-540,"elapsed":80,"user":{"displayName":"佐藤廉","userId":"11241164536858674651"}}},"execution_count":102,"outputs":[]},{"cell_type":"code","source":["# テスト\n","x, y = get_batch('train')\n","\n","for i in range(4):\n","  print(\"入力: \", decode(x[i].tolist()))\n","  print(\"正解: \", decode(y[i].tolist()))\n","  print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oiPTPIQ2dfDo","executionInfo":{"status":"ok","timestamp":1743929599570,"user_tz":-540,"elapsed":17,"user":{"displayName":"佐藤廉","userId":"11241164536858674651"}},"outputId":"da72b5d5-68a9-40db-9b04-ad36a3ca4ea5"},"execution_count":103,"outputs":[{"output_type":"stream","name":"stdout","text":["入力:  た説諭を加えた。\n","正解:  説諭を加えた。新\n","\n","入力:  一人一人の前へ行\n","正解:  人一人の前へ行っ\n","\n","入力:  やすい所を空けて\n","正解:  すい所を空けて、\n","\n","入力:  さんに伺っていい\n","正解:  んに伺っていい質\n","\n"]}]},{"cell_type":"code","source":["# 1. モデルの作成\n","import torch\n","import torch.nn as nn\n","\n","# モデルクラス\n","class CharRNN(nn.Module):\n","  def __init__(self, vocab_size, embed_size, hidden_size, block_size):\n","    super(CharRNN, self).__init__()\n","    self.block_size = block_size\n","    self.embedding = nn.Embedding(vocab_size, embed_size)\n","    self.rnn = nn.RNN(embed_size, hidden_size, batch_first=True)\n","    self.fc = nn.Linear(hidden_size, vocab_size)\n","\n","  def forward(self, x, h0=None):\n","    # 埋め込み層\n","    x = self.embedding(x)\n","    # RNN層\n","    out, h0 = self.rnn(x, h0)\n","    # 最終層の出力\n","    out = self.fc(out)\n","    return out, h0\n","\n"],"metadata":{"id":"rtMqghdOeBfu","executionInfo":{"status":"ok","timestamp":1743929602337,"user_tz":-540,"elapsed":23,"user":{"displayName":"佐藤廉","userId":"11241164536858674651"}}},"execution_count":104,"outputs":[]},{"cell_type":"code","source":["# 2. モデルの初期化\n","# ハイパーパラメータ\n","vocab_size = len(chars)  # 使用する文字の数\n","embed_size = 64  # 埋め込み層のサイズ\n","hidden_size = 512  # 隠れ層のサイズ\n","block_size = 8  # 入力サイズ\n","\n","# モデルの初期化\n","model = CharRNN(vocab_size, embed_size, hidden_size, block_size)\n","\n","# 損失関数 (CrossEntropyLoss)\n","loss_fn = nn.CrossEntropyLoss()\n","\n","# 最適化関数 (Adam)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"],"metadata":{"id":"5azhcMwzfP_x","executionInfo":{"status":"ok","timestamp":1743929979394,"user_tz":-540,"elapsed":17,"user":{"displayName":"佐藤廉","userId":"11241164536858674651"}}},"execution_count":120,"outputs":[]},{"cell_type":"code","source":["# 3. 学習の実行\n","epochs = 15000\n","for epoch in range(epochs):\n","  model.train()\n","  optimizer.zero_grad()  # 勾配の初期化\n","\n","  # バッチデータを取得\n","  x_batch, y_batch = get_batch('train')  # 'train'を使って訓練データを取得\n","\n","  # モデルの予測\n","  output, _ = model(x_batch)\n","\n","  # 損失計算\n","  loss = loss_fn(output.view(-1, vocab_size), y_batch.view(-1))\n","\n","  # 誤差逆伝播\n","  loss.backward()\n","\n","  # パラメータの更新\n","  optimizer.step()\n","\n","  if epoch % 100 == 0:  # 100回ごとに損失を表示\n","    print(f\"Epoch {epoch}, Loss: {loss.item()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-wHUOr2VjJq9","executionInfo":{"status":"ok","timestamp":1743930457710,"user_tz":-540,"elapsed":182841,"user":{"displayName":"佐藤廉","userId":"11241164536858674651"}},"outputId":"e1c133e3-2097-4a40-ef86-d489c6d56c46"},"execution_count":121,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0, Loss: 7.815550327301025\n","Epoch 100, Loss: 4.987680912017822\n","Epoch 200, Loss: 5.18065881729126\n","Epoch 300, Loss: 4.88184928894043\n","Epoch 400, Loss: 3.872058153152466\n","Epoch 500, Loss: 4.3108229637146\n","Epoch 600, Loss: 4.652576446533203\n","Epoch 700, Loss: 4.68040132522583\n","Epoch 800, Loss: 3.9063515663146973\n","Epoch 900, Loss: 4.116420269012451\n","Epoch 1000, Loss: 5.202846050262451\n","Epoch 1100, Loss: 4.160465240478516\n","Epoch 1200, Loss: 4.524961948394775\n","Epoch 1300, Loss: 3.7046256065368652\n","Epoch 1400, Loss: 4.0689778327941895\n","Epoch 1500, Loss: 4.217362880706787\n","Epoch 1600, Loss: 3.958566427230835\n","Epoch 1700, Loss: 3.5431199073791504\n","Epoch 1800, Loss: 3.9945807456970215\n","Epoch 1900, Loss: 4.518771648406982\n","Epoch 2000, Loss: 3.9191927909851074\n","Epoch 2100, Loss: 3.3753879070281982\n","Epoch 2200, Loss: 2.48144793510437\n","Epoch 2300, Loss: 4.096367359161377\n","Epoch 2400, Loss: 3.4752001762390137\n","Epoch 2500, Loss: 4.134529113769531\n","Epoch 2600, Loss: 6.295478820800781\n","Epoch 2700, Loss: 4.041027545928955\n","Epoch 2800, Loss: 4.248793601989746\n","Epoch 2900, Loss: 5.027781009674072\n","Epoch 3000, Loss: 3.7066328525543213\n","Epoch 3100, Loss: 3.800658941268921\n","Epoch 3200, Loss: 2.8305673599243164\n","Epoch 3300, Loss: 4.754134178161621\n","Epoch 3400, Loss: 4.423999309539795\n","Epoch 3500, Loss: 3.5776782035827637\n","Epoch 3600, Loss: 2.7931084632873535\n","Epoch 3700, Loss: 3.8557417392730713\n","Epoch 3800, Loss: 3.2758374214172363\n","Epoch 3900, Loss: 3.851869821548462\n","Epoch 4000, Loss: 3.430199384689331\n","Epoch 4100, Loss: 3.3191044330596924\n","Epoch 4200, Loss: 4.848240852355957\n","Epoch 4300, Loss: 3.916217803955078\n","Epoch 4400, Loss: 3.9902873039245605\n","Epoch 4500, Loss: 3.921104907989502\n","Epoch 4600, Loss: 3.8033504486083984\n","Epoch 4700, Loss: 4.513980865478516\n","Epoch 4800, Loss: 4.655035018920898\n","Epoch 4900, Loss: 4.660723686218262\n","Epoch 5000, Loss: 3.332416534423828\n","Epoch 5100, Loss: 5.356889724731445\n","Epoch 5200, Loss: 3.782336711883545\n","Epoch 5300, Loss: 3.8151960372924805\n","Epoch 5400, Loss: 4.845617294311523\n","Epoch 5500, Loss: 2.9959146976470947\n","Epoch 5600, Loss: 4.339866638183594\n","Epoch 5700, Loss: 3.197895050048828\n","Epoch 5800, Loss: 3.203845739364624\n","Epoch 5900, Loss: 4.402347564697266\n","Epoch 6000, Loss: 3.295924425125122\n","Epoch 6100, Loss: 3.8322341442108154\n","Epoch 6200, Loss: 3.736189842224121\n","Epoch 6300, Loss: 3.763712167739868\n","Epoch 6400, Loss: 3.20408296585083\n","Epoch 6500, Loss: 4.716771125793457\n","Epoch 6600, Loss: 3.7524352073669434\n","Epoch 6700, Loss: 3.701617479324341\n","Epoch 6800, Loss: 3.4372096061706543\n","Epoch 6900, Loss: 3.335167169570923\n","Epoch 7000, Loss: 3.4637489318847656\n","Epoch 7100, Loss: 4.134737491607666\n","Epoch 7200, Loss: 4.104917526245117\n","Epoch 7300, Loss: 2.142228841781616\n","Epoch 7400, Loss: 3.5206634998321533\n","Epoch 7500, Loss: 4.368810176849365\n","Epoch 7600, Loss: 4.06843900680542\n","Epoch 7700, Loss: 3.339871406555176\n","Epoch 7800, Loss: 2.797842502593994\n","Epoch 7900, Loss: 4.49498176574707\n","Epoch 8000, Loss: 3.3715872764587402\n","Epoch 8100, Loss: 3.955500602722168\n","Epoch 8200, Loss: 3.999243974685669\n","Epoch 8300, Loss: 4.0374956130981445\n","Epoch 8400, Loss: 2.9858572483062744\n","Epoch 8500, Loss: 3.508274555206299\n","Epoch 8600, Loss: 3.922236204147339\n","Epoch 8700, Loss: 4.1591877937316895\n","Epoch 8800, Loss: 4.103058338165283\n","Epoch 8900, Loss: 4.161946773529053\n","Epoch 9000, Loss: 3.539142608642578\n","Epoch 9100, Loss: 2.930453062057495\n","Epoch 9200, Loss: 2.6289520263671875\n","Epoch 9300, Loss: 2.4232826232910156\n","Epoch 9400, Loss: 3.220384359359741\n","Epoch 9500, Loss: 3.602238893508911\n","Epoch 9600, Loss: 3.3013076782226562\n","Epoch 9700, Loss: 2.9055418968200684\n","Epoch 9800, Loss: 3.3153746128082275\n","Epoch 9900, Loss: 3.5222513675689697\n","Epoch 10000, Loss: 4.017694473266602\n","Epoch 10100, Loss: 4.028934955596924\n","Epoch 10200, Loss: 3.750375509262085\n","Epoch 10300, Loss: 3.6972341537475586\n","Epoch 10400, Loss: 3.5622501373291016\n","Epoch 10500, Loss: 3.5051803588867188\n","Epoch 10600, Loss: 3.5147769451141357\n","Epoch 10700, Loss: 2.9452507495880127\n","Epoch 10800, Loss: 4.5547661781311035\n","Epoch 10900, Loss: 3.249920129776001\n","Epoch 11000, Loss: 4.355044841766357\n","Epoch 11100, Loss: 3.5457000732421875\n","Epoch 11200, Loss: 4.045596122741699\n","Epoch 11300, Loss: 4.502405643463135\n","Epoch 11400, Loss: 3.7788166999816895\n","Epoch 11500, Loss: 3.7256813049316406\n","Epoch 11600, Loss: 4.78558349609375\n","Epoch 11700, Loss: 3.1046955585479736\n","Epoch 11800, Loss: 3.0429303646087646\n","Epoch 11900, Loss: 3.7710139751434326\n","Epoch 12000, Loss: 3.3520023822784424\n","Epoch 12100, Loss: 3.4242985248565674\n","Epoch 12200, Loss: 3.046760082244873\n","Epoch 12300, Loss: 3.6070616245269775\n","Epoch 12400, Loss: 3.346813201904297\n","Epoch 12500, Loss: 3.4988420009613037\n","Epoch 12600, Loss: 4.873717784881592\n","Epoch 12700, Loss: 3.5913913249969482\n","Epoch 12800, Loss: 3.597322940826416\n","Epoch 12900, Loss: 2.828192710876465\n","Epoch 13000, Loss: 2.645937919616699\n","Epoch 13100, Loss: 3.093977928161621\n","Epoch 13200, Loss: 3.5071165561676025\n","Epoch 13300, Loss: 4.924522399902344\n","Epoch 13400, Loss: 3.8851542472839355\n","Epoch 13500, Loss: 3.752601385116577\n","Epoch 13600, Loss: 3.880579948425293\n","Epoch 13700, Loss: 2.8764891624450684\n","Epoch 13800, Loss: 4.311498165130615\n","Epoch 13900, Loss: 3.4701058864593506\n","Epoch 14000, Loss: 3.680119514465332\n","Epoch 14100, Loss: 3.5933027267456055\n","Epoch 14200, Loss: 3.6351852416992188\n","Epoch 14300, Loss: 3.674299716949463\n","Epoch 14400, Loss: 3.713810443878174\n","Epoch 14500, Loss: 3.3208084106445312\n","Epoch 14600, Loss: 3.6208527088165283\n","Epoch 14700, Loss: 3.9592702388763428\n","Epoch 14800, Loss: 3.4081318378448486\n","Epoch 14900, Loss: 3.089306592941284\n"]}]},{"cell_type":"code","source":["# 4. モデルによる文字生成\n","# モデルの評価モードに切り替え\n","model.eval()\n","\n","# 初期の文字列を設定\n","start_str = \"吾輩は\"\n","\n","# 文字列を生成する関数\n","def generate(model, start_str, max_len=100, temperature=1.0):\n","  # 文字列のリストをインデックスに変換\n","  input_str = [stoi.get(c, stoi[' ']) for c in start_str]\n","  # input_tensor = torch.tensor(input_str).unsqueeze(0)  # バッチサイズ１で入力\n","  input_tensor = torch.tensor(input_str).unsqueeze(0)\n","\n","  generated_str = start_str  # 初期文字列を保存\n","\n","  # 初期隠れ状態を設定\n","  h0 = None\n","\n","  for _ in range(max_len):\n","    # モデルの出力を取得\n","    output, h0 = model(input_tensor, h0)\n","\n","    # 出力の最後の時刻を取り出し、確率分布を計算\n","    logits = output[0, -1, :] / temperature\n","    probabilities = torch.softmax(logits, dim=-1)\n","\n","    # 次の文字を確率的にサンプリング\n","    next_char_idx = torch.multinomial(probabilities, 1).item()\n","\n","    # インデックスを文字に戻す\n","    # next_char = stoi[next_char_idx]\n","    next_char = itos.get(next_char_idx, ' ')\n","\n","    # 生成された文字を追加\n","    generated_str += next_char\n","\n","    # 次の入力として最後に生成した文字を使用\n","    input_tensor = torch.tensor([next_char_idx]).unsqueeze(0)\n","\n","  return generated_str\n"],"metadata":{"id":"CQ9qRpR5sZ_N","executionInfo":{"status":"ok","timestamp":1743931176745,"user_tz":-540,"elapsed":20,"user":{"displayName":"佐藤廉","userId":"11241164536858674651"}}},"execution_count":122,"outputs":[]},{"cell_type":"code","source":["# 初期の文字列を設定\n","start_str = \"吾輩は\"\n","\n","# 文字列を生成\n","generated_text = generate(model, start_str, max_len=100, temperature=0.7)\n","\n","# 生成された文字列を表示\n","print(\"生成された文字列:\")\n","print(generated_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1oQOX1vZHbRU","executionInfo":{"status":"ok","timestamp":1743931177790,"user_tz":-540,"elapsed":512,"user":{"displayName":"佐藤廉","userId":"11241164536858674651"}},"outputId":"fafc33f3-cc77-4a3e-ee6f-2bc9eb7c57ce"},"execution_count":123,"outputs":[{"output_type":"stream","name":"stdout","text":["生成された文字列:\n","吾輩は温泉はないように黒い出の間の前がありました。その自分の美しかりまではかっただけれ、あとんから読まらんじゃない。二三度\n","「私の前に立くないで、どった。先生は、私の運命を吹き消えないのです。Ｋが父といった\n"]}]},{"cell_type":"code","source":["\n"],"metadata":{"id":"R5_chgNGUWN3"},"execution_count":null,"outputs":[]}]}